value   = fun(GlobalParams),
par     = GlobalParams,
counts  = c("function"=iter),
hist    = ans[1:iter,,drop=FALSE]
), class="abc_answer"
))
}
#' @export
#' @param x An object of class \code{abc_answer}.
#' @rdname abc_optim
print.abc_answer <- function(x, ...) {
cat("An object of class -abc_answer- (Artificial Bee Colony Optim.):")
str(x)
invisible(x)
}
# ################################################################################
# # Ejemplos
# ################################################################################
#
# X <- c(3,2,3,1)
#
# # Funcion de matching
# fun <- function(lambda, x0, X, M)
# {
#   norm((x0 - X)*lambda, type="2") + exp(abs(sum(lambda > 0) - M))
# }
#
# # Mejor vecino para
# #  x0 = 2
# #  X  = c(3,2,3,1)
# #  M  = 1
# # El mejor resultado debe ser [0,1,0,0]
# x1 <- abc_optim(rep(0,4), fun, x0=2, X=X, M=1, lb=0, ub=1, optiinteger=T)
# x1
#
# # Mejores dos vecinos para
# #  x0 = 3
# #  X  = c(3,2,3,1)
# #  M  = 2
# # El mejor resultado debe ser [1,0,1,0]
# x2 <- abc_optim(rep(0,4), fun, x0=3, X=X, M=2, lb=0, ub=1, optiinteger=T)
# x2
#
# ################################################################################
# # Definicion de la funcion
# fun <- function(x) {
#   -cos(x[1])*cos(x[2])*exp(-((x[1] - pi)^2 + (x[2] - pi)^2))
# }
#
# abc_optim(rep(0,2), fun, lb=-5, ub=5, criter=50)
#
# optim(rep(0,2), fn=fun) #lower=-5,upper=5)
#
# ################################################################################
# # Definicion de la funcion
#
# fun <- function(x) {
#   -4+(x[1]^2 + x[2]^2)
# }
#
# abc_optim(c(1,1), fn=fun, lb=-100000, ub=100000,criter=100)
#
# ################################################################################
# # Definicion de la funcion
#
# fun <- function(x) {
#   -(x^4 - 2*x^2 - 8)
# }
#
# abc_optim(0, fn=fun, lb=-2, ub=2,criter=100)
# #
# library(microbenchmark)
# const <- 2
# fun <- function(x) {
#   -cos(x[1])*cos(x[2])*exp(-((x[1] - pi)^const + (x[2] - pi)^const))
# }
#
# microbenchmark(
#   ABC_R = abc_optim(rep(0,2), fun, lb=-20, ub=20, criter=20, maxCycle = 20),
#   ABC_CPP = abc_cpp(rep(0,2), fun, lb=-20, ub=20, criter=20, maxCycle = 20),
#   times=100
# )
fun <- function(x) {
-cos(x[1])*cos(x[2])*exp(-((x[1] - pi)^2 + (x[2] - pi)^2))
}
ans0 <- abc_optim(rep(0,2), fun, lb=-10, ub=10, criter=50)
ans0[c("par", "counts", "value")]
ans1 <- abc_cpp(rep(0,2), fun, lb=-10, ub=10, criter=50)
ans1[c("par", "counts", "value")]
abc_cpp_ <- function(par, fn, lb, ub, FoodNumber = 20L, limit = 100L, maxCycle = 1000L, criter = 50L) {
.Call('ABCoptim_abc_cpp_', PACKAGE = 'ABCoptim', par, fn, lb, ub, FoodNumber, limit, maxCycle, criter)
}
fun <- function(x) {
-cos(x[1])*cos(x[2])*exp(-((x[1] - pi)^2 + (x[2] - pi)^2))
}
ans0 <- abc_optim(rep(0,2), fun, lb=-10, ub=10, criter=50)
ans0[c("par", "counts", "value")]
ans1 <- abc_cpp(rep(0,2), fun, lb=-10, ub=10, criter=50)
ans1[c("par", "counts", "value")]
# Artificial bee colony
rm(list=ls())
# Control Parameters of ABC algorithm
NP          <- 40   # The number of colony size (employed bees+onlooker bees)
FoodNumber  <- NP/2 # The number of food sources equals the half of the colony size
limit       <- 50  # A food source which could not be improved through "limit" trials is abandoned by its employed bee
maxCycle    <- 1000  # The number of cycles for foraging {a stopping criteria}
# Problem specific variables
D           <- 4     # The number of parameters of the problem to be optimized
lb          <- 0 # Lower bound of the parameters.
ub          <- 1  # Upper bound of the parameters.
optiinteger <- TRUE
# How many times to see robustness
runtime     <- 1    # Algorithm can be run many times in order to see its robustness
Foods       <- matrix(double(FoodNumber*D), nrow=FoodNumber)
f           <- double(FoodNumber)
fitness     <- double(FoodNumber)
trial       <- double(FoodNumber)
prob        <- double(FoodNumber)
solution    <- double(D)
ObjValSol   <- double(1)
FitnessSol  <- double(1)
neighbour   <- integer(1)
param2change<- integer(1)
GlobalMin   <- double(1)
GlobalParams<- double(D)
GlobalMins  <- double(runtime)
r           <- integer(1)
# Function
fun1 <- function(x) x[1]^2 - 2*x[2]
# Definicion de la funcion
fun3 <- function(x) {
-cos(x[1])*cos(x[2])*exp(-((x[1] - pi)^2 + (x[2] - pi)^2))
}
fun <- function(lambda, x0 = 2, X = c(3,2,3,1), M = 1)
{
norm(x0 - X%*%lambda) + exp(abs(sum(lambda > 0) - M))
}
#fun <- function(...) fun2(...)*-1
# Fitness function
CalculateFitness <- function(fun)
{
if (fun >= 0) return(1/(fun + 1))
else return(1 + abs(fun))
}
# CalculateFitness(f[1])
# The best food source is memorized
MemorizeBestSource <- function()
{
for(i in seq(1,FoodNumber))
{
if (f[i] < GlobalMin)
{
GlobalMin <<- f[i]
for (j in seq(1,D))
{
GlobalParams[j]<<-Foods[i,j]
}
}
}
}
# MemorizeBestSource()
# Variables are initialized in the range [lb,ub]. If each parameter has different range, use arrays lb[j], ub[j] instead of lb and ub
# Counters of food sources are also initialized in this function
init <- function(index)
{
for (j in 1:D)
{
r <- runif(1)
if (optiinteger) Foods[index,j] <<- r > .5
else Foods[index,j] <<- r*(ub-lb) + lb
solution[j] <<- Foods[index,j]
}
f[index] <<- fun(solution)
fitness[index] <<- CalculateFitness(f[index]);
trial[index] <<- 0;
}
# init(2)
# All food sources are initialized
initial <- function() {
for (i in 1:FoodNumber)
{
init(i)
}
GlobalMin <<- f[1]
for (i in 1:D)
{
GlobalParams[i] <<- Foods[1,i]
}
}
# initial()
SendEmployedBees <- function()
{
for (i in 1:FoodNumber)
{
# The parameter to be changed is determined randomly
r <- runif(1)
param2change <- floor(r*D)
if (!param2change) param2change <- 1
# A randomly chosen solution is used in producing a mutant solution of the solution i
r <- runif(1)
neighbour <- floor(r*FoodNumber)
if (!neighbour) neighbour <- 1
# Randomly selected solution must be different from the solution i
while(neighbour==i)
{
r <- runif(1)
neighbour <- floor(r*FoodNumber)
if (!neighbour) neighbour <- 1
}
solution <<- Foods[i,]
# v_{ij}=x_{ij}+\phi_{ij}*(x_{kj}-x_{ij})
r <- runif(1)
if (optiinteger) solution[param2change] <<- r > 0.5
else
{
solution[param2change] <<- Foods[i,param2change]+(Foods[i,param2change]-Foods[neighbour,param2change])*(r-0.5)*2
# if generated parameter value is out of boundaries, it is shifted onto the boundaries
if (solution[param2change]<lb) solution[param2change]<<-lb
if (solution[param2change]>ub) solution[param2change]<<-ub
}
ObjValSol <<- fun(solution)
FitnessSol <<- CalculateFitness(ObjValSol)
# a greedy selection is applied between the current solution i and its mutant*/
if (FitnessSol>fitness[i])
{
# If the mutant solution is better than the current solution i, replace the solution with the mutant and reset the trial counter of solution i*/
trial[i] <<- 0;
for(j in 1:D) Foods[i,j] <<- solution[j]
f[i]<<- ObjValSol
fitness[i]<<-FitnessSol
}
else
{ # the solution i can not be improved, increase its trial counter*/
trial[i] <<- trial[i]+1
}
}
}
# A food source is chosen with the probability which is proportioal to its quality*/
# Different schemes can be used to calculate the probability values*/
# For example prob(i)=fitness(i)/sum(fitness)*/
# or in a way used in the metot below prob(i)=a*fitness(i)/max(fitness)+b*/
# probability values are calculated by using fitness values and normalized by dividing maximum fitness value*/
CalculateProbabilities <- function()
{
maxfit <<- fitness[1]
for (i in 1:FoodNumber)
{
if (fitness[i] > maxfit) maxfit <<- fitness[i]
}
for (i in 1:FoodNumber)
{
prob[i] <<- (.9*(fitness[i]/maxfit)) + .1
}
}
SendOnlookerBees <- function()
{
# Onlooker Bee phase
i <- 1
t <- 0
while (t < FoodNumber)
{
r = runif(1)
if (r < prob[i]) # choose a food source depending on its probability to be chosen
{
t <- t + 1
# The parameter to be changed is determined randomly
r <- runif(1)
param2change <- floor(r*D)
if (!param2change) param2change <- 1
# A randomly chosen solution is used in producing a mutant solution of the solution i
r = runif(1)
neighbour= floor(r*FoodNumber)
if (!neighbour) neighbour <- 1
neighbour <- (1:FoodNumber)[order(runif(FoodNumber))][1]
#Randomly selected solution must be different from the solution i*/
while(neighbour==i)
{
r = runif(1)
neighbour= floor(r*FoodNumber)
if (!neighbour) neighbour <- 1
}
solution <<- Foods[i,]
# v_{ij}=x_{ij}+\phi_{ij}*(x_{kj}-x_{ij}) */
r = runif(1)
if (optiinteger) solution[param2change] <<- r > .5
else
{
# if generated parameter value is out of boundaries, it is shifted onto the boundaries*/
if (solution[param2change]<lb) solution[param2change] <<- lb
if (solution[param2change]>ub) solution[param2change] <<- ub
solution[param2change] <<- Foods[i,param2change]+(Foods[i,param2change]-Foods[neighbour,param2change])*(r-0.5)*2
}
ObjValSol <<- fun(solution)
FitnessSol <<- CalculateFitness(ObjValSol)
# a greedy selection is applied between the current solution i and its mutant*/
if (FitnessSol>fitness[i])
{
# If the mutant solution is better than the current solution i, replace the solution with the mutant and reset the trial counter of solution i*/
trial[i] <<- 0
Foods[i,] <<- solution
f[i]<<-ObjValSol
fitness[i]<<-FitnessSol
} #if the solution i can not be improved, increase its trial counter*/
else trial[i] <<- trial[i]+1
}
i <- i + 1
if (i==FoodNumber) i <- 1
# end of onlooker bee phase
}
}
# determine the food sources whose trial counter exceeds the "limit" value. In Basic ABC, only one scout is allowed to occur in each cycle*/
SendScoutBees <- function()
{
maxtrialindex <- 1
for (i in 1:FoodNumber)
{
if (trial[i] > trial[maxtrialindex]) maxtrialindex <- i
}
if (trial[maxtrialindex] >= limit) init(maxtrialindex)
}
# Debug de las funcionts
# debug(SendEmployedBees)
# debug(SendOnlookerBees)
# Main program of the ABC algorithm
for(run in 1:runtime)
{
promedio <- 0
initial()
MemorizeBestSource()
for (iter in 0:maxCycle)
{
SendEmployedBees() # ; print("enviados")
CalculateProbabilities() # ; print("probab")
SendOnlookerBees() # ; print("lookon")
MemorizeBestSource() # ; print("mem")
SendScoutBees() # ; print("scouts")
}
for(j in 1:D)
{
message(sprintf("GlobalParam[%d]: %f",j,GlobalParams[j]))
}
message(sprintf("%d. run: %f",run,GlobalMin))
GlobalMins[run] <- GlobalMin
promedio <- promedio + GlobalMin
}
invisible(readline("\nPress <return> to continue: "))
invisible(readline("\nPress <return> to continue: "))
###############################################################################
# Some examples of ABC algorithm
# Author: George G. Vega
################################################################################
pause <- function() {
invisible(readline("\nPress <return> to continue: "))
}
pause()
## 2D Rosenbrock Banana function, global minimum at about (1,1)
fr <- function(x) 100 * (x[2] - x[1]^2)^2 + (1 - x[1])^2
pause()
abc_optim(c(1,1), fr, lb=-2.028, ub=2.028, criter=200)
## 5D sphere, global minimum at about (0,0,0,0,0)
fs <- function(x) sum(x^2)
pause()
abc_optim(rep(10,5), fs, lb=-100, ub=100, criter=200)
## "wild" function , global minimum at about -15.81515
pause()
10*sin(0.3*x)*sin(1.3*x^2) + 0.00001*x^4 + 0.2*x+80
abc_optim(50, fw, lb=-100, ub=100, criter=100)
## Griewank function, global minimum at 0
pause()
fg <- function(x)
sum(x*x)/4000-prod(cos(x/sqrt(1:2)))+1
abc_optim(50, fg, lb=-100, ub=100, criter=100)
# Rastrigin function, global minimum at (0,0)
pause()
20 + x[1]^2 + x[2]^2 - 10*(cos(2*pi*x[1]) + cos(2*pi*x[2]))
abc_optim(rep(50,2), fra, lb=-100, ub=100, criter=100)
# 10D Rastrigin function, global minimum at 0
pause()
abc_optim(rep(50,10), fra10, lb=-600, ub=600, criter=500)
#Reference Paper: Xin-She Yang, Nature-Inspired Metaheuristic Algorithms (second edition), pg 81-89, Luniver Press-2010
#You can either give your own input while running Firefly_algo in the bottom of this page or can leave default
#Inputs: no_firefly (total number of fireflies), N_iteration (number of timesteps),alpha (Randomness),betmin (Minimum value of beta (the attractiveness parameter)),gamma(Absorption coefficient), rng (minumum and maximum value), Fun (desired function to optimize)
firefly_algo <- function (no_firefly,N_iteration,alpha, betamin, gamma,rng,FunA = Fun){
#Check input parameters (otherwise set as default values)
# the input parameter is assumed in sequence
nargin <- nargs()
if (nargin < 1){
rng <-c(-1,1)
para <- c(20,50,0.25,0.20,1)
}
#Assume only one input parameter i.e. no_firefly is only passed to the function then rest of the parameter is initialized by the function
else if (nargin<2){
para <-c(no_firefly,50,0.25,0.20,1)
rng <-c(-1,1)
}
else if (nargin < 3){
para <-c(no_firefly,N_iteration,0.25,0.20,1)
rng <-c(-1,1)
}
else if (nargin < 4){
para <-c(no_firefly,N_iteration,alpha,0.20,1)
rng <-c(-1,1)
}
else if (nargin < 5){
para <-c(no_firefly,N_iteration,alpha, betamin,1)
rng <-c(-1,1)
}
else if (nargin < 6){
para <-c(no_firefly,N_iteration,alpha, betamin, gamma )
rng <-c(-1,1)
}
else {
rng<-c(rng[1],rng[2])
para <-c(no_firefly,N_iteration,alpha, betamin,gamma)
}
#Assign values to each variables
no_firefly <- para[1]
MaxGeneration <- para[2]
alpha <- para[3]
betamin <- para[4]
gamma <- para[5]
#Generate the initial locations of n fireflies
init_ffa <- function (no_firefly,rng){
ak<-rng[2] - rng[1]
x1n <- t(matrix(runif(no_firefly)*ak + rng[1]))
x2n <- t(matrix(runif(no_firefly)*ak + rng[1]))
Lightn <-matrix (0,nrow(x1n),ncol(x1n))
return(list(x1n,x2n,Lightn))		#initial value before function evaluations
}
#Make sure the fireflies are within the range
findrange_r <- function (x1n,x2n, rng){
for (i in 1: length(x1n)){
if (x1n[i] <= rng[1]){
x1n[i] <- rng[1]
}
if (x1n[i] >= rng[2]){
x1n[i] <- rng[2]
}
if (x2n[i]<= rng[1]){
x2n[i] <-rng[1]
}
if (x2n[i] >= rng[2]){
x2n[i]=rng[2]
}
}
return (list(x1n,x2n))
}
#Move all fireflies to the better locations
ffa_move <-function (x1n,x2n,Lightn,x1o,x2o,Lighto,alpha,gamma,rng){
ni = length(x1n)
nj= length(x1o)
for (i in 1:ni){
for (j in 1:nj){
r = sqrt((x1n[i]-x1o[j])^2 + (x2n[i]-x2o[j])^2) # This is the euclidian distance but you can change it according to ur needs
if (Lightn[i]<Lighto[j]){
beta0 =1
#if you are not using betamin then beta <- beta0 * exp((-gamma) * r^2)
beta<-(beta0-betamin)* exp(-gamma * r^2)+ betamin
x1n[i] <- x1n[i]*(1-beta) + (x1o[j]*beta) +(alpha * (runif(1)-0.5)) # * exp(-0.2*log(downscale)))
x2n[i] <- x2n[i]*(1-beta)+ (x2o[j] * beta) + (alpha * (runif(1) -0.5))	# * exp(-0.2*log(downscale)))
}
}
}
fdr <- findrange_r(x1n,x2n,rng);
x1n <-fdr[[1]]
x2n <-fdr[[2]]
return (list(x1n,x2n))
}
## This function is optional, as it is not in the original FA. The idea to reduce randomness is to increase the convergence, however, if you reduce randomness too quickly, then premature convergence can occur. So use with care.
alpha_new<-function(alpha,NGen){
#alpha_n=alpha_0(1-delta)^NGen=0.005
#alpha_0=0.9
delta<-1-(0.005/0.9)^(1/NGen)
alpha<-(1-delta)*alpha
}
#Initial values of an array
zn <-rep((10^100),no_firefly)
As<-init_ffa(no_firefly,rng)
x1n <-As[[1]]
x2n <-As[[2]]
Lightn <-As[[3]]
for (i in 1:MaxGeneration){
alpha=alpha_new(alpha,MaxGeneration) # This is optional
prob <- c(0.8,0.2)
zn <-FunA(x1n,x2n)
# Ranking the fireflies by their light intensity
tmp<-sort(zn,index.return=TRUE)
Lightn<-tmp$x
idx<-tmp$ix  #idx is index
##Reordering of fireflies by their light intensity
x1n<-x1n[idx]
x2n=x2n[idx]
# initial value of xo, yo and Lighto is changed here
x1o<-x1n
x2o<-x2n
Lighto<-Lightn
# Move all fireflies to the better locations
tmp_move<- ffa_move(x1n,x2n,Lightn,x1o,x2o,Lighto,alpha,gamma,rng)
x1n <-tmp_move[[1]]
x2n <- tmp_move[[2]]
}
# Output
best <-cbind(x1n,x2n,Lightn)
return (best)
}
set.seed(1)
#Function to optimize (User might want to change this )
Fun <- function(x,y){
str1=exp(-(x-4)^2-(y-4)^2)+exp(-(x+4)^2-(y-4)^2)+2*exp(-x^2-(y+4)^2)+2*exp(-x^2-y^2)
return (str1)
}
firefly_algo()
